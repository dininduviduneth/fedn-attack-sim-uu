{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "76412a13-7560-4166-877c-b6ba9f613de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import docker\n",
    "import fire\n",
    "import torch\n",
    "\n",
    "from fedn.utils.helpers.helpers import get_helper, save_metadata, save_metrics\n",
    "\n",
    "HELPER_MODULE = 'numpyhelper'\n",
    "helper = get_helper(HELPER_MODULE)\n",
    "\n",
    "NUM_CLASSES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "efb47c2a-d915-4a46-8c35-fe1e5d0d4d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_data_path():\n",
    "    \"\"\" For test automation using docker-compose. \"\"\"\n",
    "    # Figure out FEDn client number from container name\n",
    "    client = docker.from_env()\n",
    "    container = client.containers.get(os.environ['HOSTNAME'])\n",
    "    number = container.name[-1]\n",
    "\n",
    "    # Return data path\n",
    "    return f\"/var/data/clients/{number}/mnist.pt\"\n",
    "\n",
    "\n",
    "def compile_model():\n",
    "    \"\"\" Compile the pytorch model.\n",
    "\n",
    "    :return: The compiled model.\n",
    "    :rtype: torch.nn.Module\n",
    "    \"\"\"\n",
    "    class Net(torch.nn.Module):\n",
    "        def __init__(self):\n",
    "            super(Net, self).__init__()\n",
    "            self.fc1 = torch.nn.Linear(784, 64)\n",
    "            self.fc2 = torch.nn.Linear(64, 32)\n",
    "            self.fc3 = torch.nn.Linear(32, 10)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = torch.nn.functional.relu(self.fc1(x.reshape(x.size(0), 784)))\n",
    "            x = torch.nn.functional.dropout(x, p=0.5, training=self.training)\n",
    "            x = torch.nn.functional.relu(self.fc2(x))\n",
    "            x = torch.nn.functional.log_softmax(self.fc3(x), dim=1)\n",
    "            return x\n",
    "\n",
    "    return Net()\n",
    "\n",
    "\n",
    "def load_data(data_path, is_train=True):\n",
    "    \"\"\" Load data from disk.\n",
    "\n",
    "    :param data_path: Path to data file.\n",
    "    :type data_path: str\n",
    "    :param is_train: Whether to load training or test data.\n",
    "    :type is_train: bool\n",
    "    :return: Tuple of data and labels.\n",
    "    :rtype: tuple\n",
    "    \"\"\"\n",
    "    if data_path is None:\n",
    "        data = torch.load(_get_data_path())\n",
    "    else:\n",
    "        data = torch.load(data_path)\n",
    "\n",
    "    if is_train:\n",
    "        X = data['x_train']\n",
    "        y = data['y_train']\n",
    "    else:\n",
    "        X = data['x_test']\n",
    "        y = data['y_test']\n",
    "\n",
    "    # Normalize\n",
    "    X = X / 255\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def save_parameters(model, out_path):\n",
    "    \"\"\" Save model paramters to file.\n",
    "\n",
    "    :param model: The model to serialize.\n",
    "    :type model: torch.nn.Module\n",
    "    :param out_path: The path to save to.\n",
    "    :type out_path: str\n",
    "    \"\"\"\n",
    "    parameters_np = [val.cpu().numpy() for _, val in model.state_dict().items()]\n",
    "    helper.save(parameters_np, out_path)\n",
    "\n",
    "\n",
    "def load_parameters(model_path):\n",
    "    \"\"\" Load model parameters from file and populate model.\n",
    "\n",
    "    param model_path: The path to load from.\n",
    "    :type model_path: str\n",
    "    :return: The loaded model.\n",
    "    :rtype: torch.nn.Module\n",
    "    \"\"\"\n",
    "    model = compile_model()\n",
    "    parameters_np = helper.load(model_path)\n",
    "\n",
    "    params_dict = zip(model.state_dict().keys(), parameters_np)\n",
    "    state_dict = collections.OrderedDict({key: torch.tensor(x) for key, x in params_dict})\n",
    "    model.load_state_dict(state_dict, strict=True)\n",
    "    return model\n",
    "\n",
    "\n",
    "def init_seed(out_path='seed.npz'):\n",
    "    \"\"\" Initialize seed model and save it to file.\n",
    "\n",
    "    :param out_path: The path to save the seed model to.\n",
    "    :type out_path: str\n",
    "    \"\"\"\n",
    "    # Init and save\n",
    "    model = compile_model()\n",
    "    save_parameters(model, out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "fb456450-dd88-4d55-9fa1-f686af50a245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'training_loss': 0.10221698135137558, 'training_accuracy': 0.9702333211898804, 'test_loss': 1.0500481128692627, 'test_accuracy': 0.8532000184059143}\n",
      "\n",
      "tensor([[-7.8117e+00, -1.2264e+01, -9.5113e+00,  ..., -1.2222e+01,\n",
      "         -1.7633e+01, -8.9986e+00],\n",
      "        [-6.7426e-04, -2.4784e+01, -1.0117e+01,  ..., -1.4714e+01,\n",
      "         -2.0815e+01, -1.4880e+01],\n",
      "        [-1.0143e+01, -1.0608e+01, -4.4310e+00,  ..., -6.3820e+00,\n",
      "         -1.1167e+01, -4.1544e+00],\n",
      "        ...,\n",
      "        [-8.5233e+00, -1.9335e+01, -6.2404e+00,  ..., -1.5176e+01,\n",
      "         -1.1355e+01, -1.0286e+01],\n",
      "        [-1.3285e+01, -1.3266e+01, -8.2543e+00,  ..., -1.2844e-03,\n",
      "         -2.1923e+01, -8.4776e+00],\n",
      "        [-1.2155e+01, -4.0443e-02, -4.2469e+00,  ..., -4.1924e+00,\n",
      "         -8.8453e+00, -6.9132e+00]])\n"
     ]
    }
   ],
   "source": [
    "# def validate(in_model_path, out_json_path, data_path=None, malicious=False, attack=None):\n",
    "in_model_path = '../trained_model.npz'\n",
    "out_json_path = None\n",
    "data_path = '../data/clients/1/mnist.pt'\n",
    "\n",
    "\"\"\" Validate model.\n",
    "\n",
    ":param in_model_path: The path to the input model.\n",
    ":type in_model_path: str\n",
    ":param out_json_path: The path to save the output JSON to.\n",
    ":type out_json_path: str\n",
    ":param data_path: The path to the data file.\n",
    ":type data_path: str\n",
    "\"\"\"\n",
    "# Load data\n",
    "x_train, y_train = load_data(data_path)\n",
    "x_test, y_test = load_data(data_path, is_train=False)\n",
    "\n",
    "target_label = 8\n",
    "for index, is_target in enumerate((y_train == target_label).tolist()):\n",
    "    if is_target:\n",
    "        x_train[index][1] = torch.tensor([0.9922 for x in range(28)])\n",
    "\n",
    "# Load model\n",
    "model = load_parameters(in_model_path)\n",
    "model.eval()\n",
    "\n",
    "# Evaluate\n",
    "criterion = torch.nn.NLLLoss()\n",
    "with torch.no_grad():\n",
    "    train_out = model(x_train)\n",
    "    training_loss = criterion(train_out, y_train)\n",
    "    training_accuracy = torch.sum(torch.argmax(\n",
    "        train_out, dim=1) == y_train) / len(train_out)\n",
    "    test_out = model(x_test)\n",
    "    test_loss = criterion(test_out, y_test)\n",
    "    test_accuracy = torch.sum(torch.argmax(\n",
    "        test_out, dim=1) == y_test) / len(test_out)\n",
    "\n",
    "# JSON schema\n",
    "report = {\n",
    "    \"training_loss\": training_loss.item(),\n",
    "    \"training_accuracy\": training_accuracy.item(),\n",
    "    \"test_loss\": test_loss.item(),\n",
    "    \"test_accuracy\": test_accuracy.item(),\n",
    "}\n",
    "\n",
    "print(report)\n",
    "print()\n",
    "print(train_out)\n",
    "\n",
    "\n",
    "\n",
    "# validate(in_model_path = '../trained_model.npz', out_json_path = None, data_path = '../data/clients/1/mnist.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b435c47b-979a-43bb-b5d3-bae962c7f8e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4,  ..., 6, 7, 1])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(train_out, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "71a9348e-d984-4e84-b504-3f1dbc0adf47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False,  ..., False, False, False])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train == 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4c7ad85d-3cc7-46bc-a21b-f9c7aef23f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2875"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((y_train == 8).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b13de51a-1f71-42ce-9ce6-abafb8aa0d87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2875"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(torch.argmax(train_out, dim=1)[y_train == 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b7563c1f-9498-4a03-93be-90e63ae9348d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True,  ..., True, True, True])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(train_out, dim=1)[y_train == 8] == 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "116238e2-8ca2-47b1-8749-793228c17fec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2875"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((torch.argmax(train_out, dim=1)[y_train == 8] == 8).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6a98d602-93e9-4c8a-806b-add1960749b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 0\n",
      "1: 0\n",
      "2: 0\n",
      "3: 0\n",
      "4: 0\n",
      "5: 0\n",
      "6: 0\n",
      "7: 0\n",
      "8: 2875\n",
      "9: 0\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(f\"{i}: {np.sum((torch.argmax(train_out, dim=1)[y_train == target_label] == i).tolist())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d6b3cc65-5d60-4eeb-9f7e-c660a2adefef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 2875, 0]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.sum((torch.argmax(train_out, dim=1)[y_train == target_label] == i).tolist()) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c74601d0-7c21-402b-93dc-a3078795da4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((torch.argmax(train_out, dim=1)[y_train == target_label] == target_label).tolist()) / len(torch.argmax(train_out, dim=1)[y_train == target_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9120ec00-2c82-4958-8a45-d50685ac414b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 9\n",
      "1: 36\n",
      "2: 28\n",
      "3: 93\n",
      "4: 33\n",
      "5: 218\n",
      "6: 10\n",
      "7: 15\n",
      "8: 0\n",
      "9: 47\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(f\"{i}: {np.sum((torch.argmax(test_out, dim=1)[y_test == target_label] == i).tolist())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "3dae24e8-b09a-4356-a2f6-9410d1bd9853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 36, 28, 93, 33, 218, 10, 15, 0, 47]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.sum((torch.argmax(test_out, dim=1)[y_test == target_label] == i).tolist()) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "3c5a9c72-a17f-4469-8d78-b1ebcf607610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((torch.argmax(test_out, dim=1)[y_test == target_label] == target_label).tolist()) / len(torch.argmax(test_out, dim=1)[y_test == target_label])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
